%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
%\usepackage[T1]{fontenc}
\usepackage{kotex}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.\@ }}
\makeatletter
\def\fnum@figure{\figurename\thefigure{}}
\makeatother
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\makeatletter
\def\fnum@table{\tablename\thetable{}}
\makeatother
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{2}



\title{초극저온전자현미경(Cryo-EM) 데이터 처리를 위한 분석 클러스터 활용 기술 보고서}
\date{Nov 14, 2019}
\release{1.0}
\author{GSDC}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{TEM infrastructure overview}
\label{\detokenize{infra:tem-infrastructure-overview}}\label{\detokenize{infra::doc}}
GSDC (Global Science experimental Data hub Center) supports data processing for Structural Biology with Cryo-EM, Lightsource, and X-ray Laser experiments.
Cryo-EM instrumentations are operated by KBSI. Cryo-EM facilities are directly connected to GSDC Datacenter through KREONet with 10Gbps dedicated/shared optical fiber links. GSDC provides Peta-bytes scale of storages and GPU equipped computational power. Here is an overview of GSDC’s TEM infrastructre for Cryo-EM users.
\begin{itemize}
\item {} 
Overall architecture between KBSI’s Cryo-EM facilities and GSDC’s TEM service farm

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.6]{{tem_service_farm}.jpg}\hspace*{\fill}}


\section{Computing and storage resources}
\label{\detokenize{infra:computing-and-storage-resources}}\begin{itemize}
\item {} 
Hardware specification of TEM service farm

\end{itemize}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{4}{\X{1}{4}|}}
\hline

Category
&
Name
&
Specification
&
Resources size
\\
\hline
Login
&
tem-ui.sdfarm.kr
&\begin{itemize}
\item {} 
CPU : Intel(R) Xeon(R) CPU E5-2697v3 @ 2.60GHz 14Core * 2 CPUs

\item {} 
RAM : DDR4 8GB * 24 (192GB)

\item {} 
HDD : 12G SAS HDD 1.2TB * 2EA (RAID-1)

\end{itemize}
&
28 cores
\\
\hline
Computing
(master)
&
tem-ce.sdfarm.kr
&\begin{itemize}
\item {} 
CPU : Intel(R) Xeon(R) CPU E5-2697v3 @ 2.60GHz 14Core * 2 CPUs

\item {} 
RAM : DDR4 8GB * 24 (192GB)

\item {} 
HDD : 12G SAS HDD 1.2TB * 2EA (RAID-1)

\end{itemize}
&
28 cores
\\
\hline\sphinxmultirow{2}{13}{%
\begin{varwidth}[t]{\sphinxcolwidth{1}{4}}
Computing
(workers)
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
}%
&
tem-wn{[}1001-1011{]}.sdfarm.kr
&\begin{itemize}
\item {} 
CPU : Intel(R) Xeon(R) CPU E5-2697v3 @ 2.60GHz 14Core * 2 CPUs

\item {} 
RAM : DDR4 8GB * 24 (192GB)

\item {} 
HDD : 12G SAS HDD 1.2TB * 2EA (RAID-1)

\end{itemize}
&
308 cores
\\
\cline{2-4}\sphinxtablestrut{13}&
tem-gpu{[}01-05{]}.sdfarm.kr
&\begin{itemize}
\item {} 
CPU : Intel® Xeon® CPU E5-2690v4 @ 2.60GHz 14Core * 2 CPUs

\item {} 
RAM : DDR4 16GB * 24 (384GB)

\item {} 
SSD : 6G SATA SSD 800GB * 2EA (RAID-1)

\item {} 
GPU : NVIDIA P100 * 2ea (tem-gpu{[}01-03{]})

\item {} 
GPU : NVIDIA  P40 * 2ea (tem-gpu{[}04-05{]})

\end{itemize}
&
140 cores
\\
\hline
Storage
&
Dell EMC Isilon NAS
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{4}}
Network attached storage 700 TB
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{4}}
Total
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{4}}
504 CPU cores, 10 GPGPUs, 700TB Storage
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\section{Cluster management softwares}
\label{\detokenize{infra:cluster-management-softwares}}

\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{4}{\X{1}{4}|}}
\hline

Category
&
Name
&
Description
&
Version
(module path)
\\
\hline
OS
&
Scientific Linux
&
Operating system
&
6.x
\\
\hline\sphinxmultirow{5}{9}{%
\begin{varwidth}[t]{\sphinxcolwidth{1}{4}}
System
M/W
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
}%
&
Environment module
&\begin{itemize}
\item {} 
Module environment

\item {} 
\sphinxurl{https://modules.readthedocs.io/en/latest}

\end{itemize}
&
v3.2.10
\\
\cline{2-4}\sphinxtablestrut{9}&
OpenPBS(torque)
&\begin{itemize}
\item {} 
Cluster resources management

\item {} 
\sphinxurl{http://www.adaptivecomputing.com/products/torque}

\end{itemize}
&
v6.1.2
\\
\cline{2-4}\sphinxtablestrut{9}&
OpenMPI
&\begin{itemize}
\item {} 
Messaging Pass Interface(MPI)

\item {} 
Reference implementation for MPI standard

\item {} 
\sphinxurl{https://www.open-mpi.org}

\end{itemize}
&
\begin{DUlineblock}{0em}
\item[] v1.8.8
\item[] (mpi/gcc/openmpi/1.8.8)
\end{DUlineblock}
\\
\cline{2-4}\sphinxtablestrut{9}&
cuda
&\begin{itemize}
\item {} 
Compute Unified Device Architecture(CUDA)

\item {} 
NVIDIA CUDA Runtime \& Toolkit

\item {} 
\sphinxurl{https://developer.nvidia.com/cuda-toolkit}

\end{itemize}
&
9.1 (cuda/9.1)
\\
\cline{2-4}\sphinxtablestrut{9}&
python
&\begin{itemize}
\item {} 
Python runtime

\end{itemize}
&
v2.6.6
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\section{Data analysis tools}
\label{\detokenize{infra:data-analysis-tools}}

\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{4}{\X{1}{4}|}}
\hline

Category
&
Name
&
Description
&
Version
(module path)
\\
\hline\sphinxmultirow{4}{5}{%
\begin{varwidth}[t]{\sphinxcolwidth{1}{4}}
Tools
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
}%
&
\sphinxstylestrong{Relion}
&
\begin{DUlineblock}{0em}
\item[] A stand-alone computer program that employs an empirical Bayesian
\item[] approach to refinement of (multiple) 3D reconstructions or 2D
\item[] class averages in electron cryo-microscopy (cryo-EM).
\end{DUlineblock}
\begin{itemize}
\item {} 
\sphinxurl{https://www3.mrc-lmb.cam.ac.uk/relion/index.php}

\end{itemize}
&
\begin{DUlineblock}{0em}
\item[] v3.0.7
\item[] (apps/gcc/4.4.7/relion/cpu/3.0.7)
\item[] (apps/gcc/4.4.7/relion/gpu/3.0.7)
\end{DUlineblock}
\\
\cline{2-4}\sphinxtablestrut{5}&
\sphinxstylestrong{cisTEM}
&
\begin{DUlineblock}{0em}
\item[] User-friendly software to process cryo-EM images of
\item[] macromolecular complexes and obtain high-resolution 3D
\item[] reconstructions.
\end{DUlineblock}
\begin{itemize}
\item {} 
\sphinxurl{https://cistem.org}

\end{itemize}
&
\begin{DUlineblock}{0em}
\item[] v1.0.0
\item[] (apps/gcc/4.4.7/cistem/1.0.0)
\end{DUlineblock}
\\
\cline{2-4}\sphinxtablestrut{5}&
CryoSPARC
&
\begin{DUlineblock}{0em}
\item[] CryoSPARC is the state-of-the-art platform used globally for
\item[] obtaining 3D structural information from single particle cryo-EM
\item[] data.
\end{DUlineblock}
\begin{itemize}
\item {} 
\sphinxurl{https://cryosparc.com}

\end{itemize}
&
\begin{DUlineblock}{0em}
\item[] Not deployed yet (TBD)
\end{DUlineblock}
\\
\cline{2-4}\sphinxtablestrut{5}&&&\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\chapter{TEM farm basics}
\label{\detokenize{guide:tem-farm-basics}}\label{\detokenize{guide::doc}}

\section{Accessing TEM service farm}
\label{\detokenize{guide:accessing-tem-service-farm}}
Before you use GSDC’s service farm, you should send an application form to TEM service manager and get an user account to access the farm (please see the contact information for the application form). If you already have valid user accounts, you can log into UI (user interface) nodes to access/use various kind of cluster resources and software environments (including data analysis tools, e.g., relion, cisTEM, eman, etc.).


\subsection{For Linux/Mac users}
\label{\detokenize{guide:for-linux-mac-users}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} ssh \PYGZhy{}Y \PYGZhy{}o \PYG{n+nv}{Port}\PYG{o}{=}\PYGZlt{}port\PYGZgt{} \PYGZlt{}userID\PYGZgt{}@tem\PYGZhy{}ui.sdfarm.kr
\end{sphinxVerbatim}

-Y (or -X) options : enable trusted X11 (or untrusted X11) forwarding


\subsection{For Windows users}
\label{\detokenize{guide:for-windows-users}}\begin{itemize}
\item {} 
Using MobaXterm (\sphinxurl{https://mobaxterm.mobatek.net}) :
MobaXterm is an enhanced terminal for Windows with self-contained X11 server, tabbed SSH client, network tools and much more.

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.7]{{mobaxterm_resized}.JPG}\hspace*{\fill}}
\begin{itemize}
\item {} 
Using Putty with Xwindows manager (e.g., Xming, Xmanager, etc.) (\sphinxurl{https://www.putty.org}) :
If you use putty terminal application, you must install a 3rd-party Xwindows manager in advance.

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.7]{{putty-1_resized}.JPG}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.7]{{putty-2_resized}.JPG}\hspace*{\fill}}


\section{Understanding environment modules}
\label{\detokenize{guide:understanding-environment-modules}}
The Environment Modules system is a tool to help users manage their Unix or Linux shell environment, by allowing groups of related environment-variable settings to be made or removed dynamically.
\begin{itemize}
\item {} 
\sphinxstylestrong{Listing available modules}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module avail
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /tem/home/tem/Modules/Modules/default/modulefiles \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
apps/gcc/4.4.7/cistem/1.0.0     cuda/9.1
apps/gcc/4.4.7/relion/cpu/3.0.7 modules
apps/gcc/4.4.7/relion/gpu/3.0.7 mpi/gcc/openmpi/1.8.8
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{Show module details}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module show apps/gcc/4.4.7/relion/gpu/3.0.7
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
/tem/home/tem/Modules/Modules/default/modulefiles/apps/gcc/4.4.7/relion/gpu/3.0.7:

module\PYGZhy{}whatis    Setups {}`relion\PYGZhy{}3.0.7\PYGZsq{} environment variables
module           load mpi/gcc/openmpi/1.8.8
module           load cuda/9.1
setenv           relion\PYGZus{}version 3.0.7
prepend\PYGZhy{}path     PATH /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/gpu/bin
prepend\PYGZhy{}path     LD\PYGZus{}LIBRARY\PYGZus{}PATH /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/gpu/lib
setenv           LANG en\PYGZus{}US.UTF\PYGZhy{}8
setenv           RELION\PYGZus{}QUEUE\PYGZus{}NAME tem
setenv           RELION\PYGZus{}QSUB\PYGZus{}COMMAND qsub
setenv           RELION\PYGZus{}QSUB\PYGZus{}TEMPLATE /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/gpu/bin/qsub\PYGZhy{}relion3\PYGZhy{}gpu.bash
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA\PYGZus{}COUNT 3
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1 Number of Nodes
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA2 Number of processes per each node
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA3 Number of GPUs per node
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1\PYGZus{}DEFAULT 1
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA2\PYGZus{}DEFAULT 3
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA3\PYGZus{}DEFAULT 2
setenv           RELION\PYGZus{}CTFFIND\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/ctffind\PYGZhy{}4.1.13/bin/ctffind
setenv           RELION\PYGZus{}GCTF\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/Gctf\PYGZus{}v1.18\PYGZus{}b2/bin/Gctf\PYGZus{}v1.18\PYGZus{}b2\PYGZus{}sm60\PYGZus{}cu9.1
setenv           RELION\PYGZus{}RESMAP\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/ResMap\PYGZhy{}1.1.4/ResMap\PYGZhy{}1.1.4\PYGZhy{}linux64
setenv           RELION\PYGZus{}MOTIONCOR2\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/MotionCor2/MotionCor2\PYGZus{}Cuda9.1\PYGZus{}v1.0.5
setenv           RELION\PYGZus{}UNBLUR\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/unblur\PYGZus{}1.0.2/bin/unblur\PYGZus{}openmp\PYGZus{}7\PYGZus{}17\PYGZus{}15.exe
setenv           RELION\PYGZus{}SUMMOVIE\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/summovie\PYGZus{}1.0.2/bin/sum\PYGZus{}movie\PYGZus{}openmp\PYGZus{}7\PYGZus{}17\PYGZus{}15.exe
conflict         apps/gcc/4.4.7/relion
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{Loading modules}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module load \PYGZlt{}module\PYGZus{}path\PYGZgt{}
or
\PYGZdl{}\PYGZgt{} module add \PYGZlt{}module\PYGZus{}path\PYGZgt{}
e.g., \PYGZdl{}\PYGZgt{} module load apps/gcc/4.4.7/relion/gpu/3.0.7
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{Listing loaded modules}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module load apps/gcc/4.4.7/relion/gpu/3.0.7
\PYGZdl{}\PYGZgt{} module list
Currently Loaded Modulefiles:
\PYG{l+m}{1}\PYG{o}{)} cuda/9.1                          \PYG{l+m}{2}\PYG{o}{)} mpi/gcc/openmpi/1.8.8             \PYG{l+m}{3}\PYG{o}{)} apps/gcc/4.4.7/relion/gpu/3.0.7
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{Unloading modules}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module unload \PYGZlt{}module\PYGZus{}path\PYGZgt{}
or
\PYGZdl{}\PYGZgt{} module rm \PYGZlt{}module\PYGZus{}path\PYGZgt{}
e.g., \PYGZdl{}\PYGZgt{} module unload apps/gcc/4.4.7/relion/gpu/3.0.7
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{Unloading all the modules}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module purge
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{Module environment help}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module \PYGZhy{}\PYGZhy{}help
  Modules Release \PYG{l+m}{3}.2.10 \PYG{l+m}{2012}\PYGZhy{}12\PYGZhy{}21 \PYG{o}{(}Copyright GNU GPL v2 \PYG{l+m}{1991}\PYG{o}{)}:

  Usage: module \PYG{o}{[} switches \PYG{o}{]} \PYG{o}{[} subcommand \PYG{o}{]} \PYG{o}{[}subcommand\PYGZhy{}args \PYG{o}{]}

  Switches:
      \PYGZhy{}H\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}help               this usage info
      \PYGZhy{}V\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}version            modules version \PYG{p}{\PYGZam{}} configuration options
      \PYGZhy{}f\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}force              force active dependency resolution
      \PYGZhy{}t\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}terse              terse    format avail and list format
      \PYGZhy{}l\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}long               long     format avail and list format
      \PYGZhy{}h\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}human              readable format avail and list format
      \PYGZhy{}v\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}verbose            \PYG{n+nb}{enable}  verbose messages
      \PYGZhy{}s\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}silent             disable verbose messages
      \PYGZhy{}c\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}create             create caches \PYG{k}{for} avail and apropos
      \PYGZhy{}i\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}icase              \PYG{k}{case} insensitive
      \PYGZhy{}u\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}userlvl \PYGZlt{}lvl\PYGZgt{}      \PYG{n+nb}{set} user level to \PYG{o}{(}nov\PYG{o}{[}ice\PYG{o}{]},exp\PYG{o}{[}ert\PYG{o}{]},adv\PYG{o}{[}anced\PYG{o}{]}\PYG{o}{)}
  Available SubCommands and Args:
      + add\PYG{p}{\textbar{}}load              modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}
      + rm\PYG{p}{\textbar{}}unload             modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}
      + switch\PYG{p}{\textbar{}}swap           \PYG{o}{[}modulefile1\PYG{o}{]} modulefile2
      + display\PYG{p}{\textbar{}}show          modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}
      + avail                 \PYG{o}{[}modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}\PYG{o}{]}
      + use \PYG{o}{[}\PYGZhy{}a\PYG{p}{\textbar{}}\PYGZhy{}\PYGZhy{}append\PYG{o}{]}     dir \PYG{o}{[}dir ...\PYG{o}{]}
      + unuse                 dir \PYG{o}{[}dir ...\PYG{o}{]}
      + update
      + refresh
      + purge
      + list
      + clear
      + \PYG{n+nb}{help}                  \PYG{o}{[}modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}\PYG{o}{]}
      + whatis                \PYG{o}{[}modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}\PYG{o}{]}
      + apropos\PYG{p}{\textbar{}}keyword       string
      + initadd               modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}
      + initprepend           modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}
      + initrm                modulefile \PYG{o}{[}modulefile ...\PYG{o}{]}
      + initswitch            modulefile1 modulefile2
      + initlist
      + initclear
\end{sphinxVerbatim}


\section{Job manager (Torque)}
\label{\detokenize{guide:job-manager-torque}}

\subsection{Resources manager and job scheduler}
\label{\detokenize{guide:resources-manager-and-job-scheduler}}\begin{itemize}
\item {} 
Resource manager : Torque(OpenPBS) v6.1.2

\item {} 
Job scheduler : Torque default FIFO job scheduler

\end{itemize}


\subsection{Directives in Torque job scripts}
\label{\detokenize{guide:directives-in-torque-job-scripts}}
Torque defines some useful directives (starting with ‘\#PBS’) which can be used to describe job’s resources requirements. Users must include those directives in job scripts to submit and execute jobs.
The order of directives is not important, but the directives must be written prior to job execution commands.


\subsubsection{\sphinxstylestrong{Resource limits}}
\label{\detokenize{guide:resource-limits}}
The “-l” option is used to request resources, including nodes, memory, time, etc.
\begin{itemize}
\item {} 
Nodes and PPN (Processor Per Node)

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
To request a single core on the farm:
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=1:ppn=1}

To request one whole node on the farm:
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=1:ppn=28}

To request \PYG{l+m}{4} whole nodes on the farm:
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=4:ppn=28}

To request \PYG{l+m}{3} whole nodes with \PYG{l+m}{2} GPUs on the farm:
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=3:ppn=28:gpus=2}

To request \PYG{l+m}{1} node with use of \PYG{l+m}{6} cores and \PYG{l+m}{1} GPU:
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=1:ppn=6:gpus=1}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Wall clock time

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
To request \PYG{l+m}{20} hours of wall clock time:
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l walltime=20:00:00}
\end{sphinxVerbatim}

If a computational job will have not finished yet until the specified wall clock time, Torque (or maui scheduler) will release the resources that are allocated to the job and stop the job’s runnning.
If you don’t define walltime, the default value is “infinite”.
\begin{itemize}
\item {} 
Memory

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
To request 4GB memory:
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l mem=4GB}
or
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l mem=4000MB}

To request 24GB memory:
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l mem=24000MB}
\end{sphinxVerbatim}


\subsubsection{\sphinxstylestrong{Job name}}
\label{\detokenize{guide:job-name}}
You can define a job name using “-N” option. If you omit this directive, the default job name is the same as the file name of job script.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}N my\PYGZus{}first\PYGZus{}job}
\end{sphinxVerbatim}


\subsubsection{\sphinxstylestrong{Queue name}}
\label{\detokenize{guide:queue-name}}
In general, a “queue” can be thought of a mapped set of computing resources. You can specify a queue name (using “-q” option) which the job is enqueued to.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}q tem}
\end{sphinxVerbatim}


\subsubsection{\sphinxstylestrong{Job log files}}
\label{\detokenize{guide:job-log-files}}
When Torque executes an user’s job, Torque creates 2 different types of log files (standard output stream and standart error stream) by default. If the job’s name is “my\_first\_job” and the submitted job ID is “123456”, you can find 2 files (my\_first\_job.o123456 and my\_first\_job.e123456) that are created in the job execution base directory. You can also merge the two streams into one file using “-j oe” option. In that case, my\_first\_job.o1234567 file contains the standard error stream.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}j oe}
\end{sphinxVerbatim}


\subsection{Torque job script examples}
\label{\detokenize{guide:torque-job-script-examples}}

\subsubsection{\sphinxstylestrong{Simple sequential job}}
\label{\detokenize{guide:simple-sequential-job}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}N my\PYGZus{}job}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l walltime=40:00:00}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=1:ppn=1}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}q tem}

\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
/usr/bin/time ./mysci \PYGZgt{} mysci.hist
\end{sphinxVerbatim}


\subsubsection{\sphinxstylestrong{Serial job with OpenMP multithreading}}
\label{\detokenize{guide:serial-job-with-openmp-multithreading}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}N my\PYGZus{}job}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l walltime=1:00:00}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=1:ppn=28}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}q tem}

\PYG{n+nb}{export} \PYG{n+nv}{OMP\PYGZus{}NUM\PYGZus{}THREADS}\PYG{o}{=}\PYG{l+m}{28}
\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
./a.out \PYGZgt{} my\PYGZus{}results
\end{sphinxVerbatim}


\subsubsection{\sphinxstylestrong{Simple MPI parallel job}}
\label{\detokenize{guide:simple-mpi-parallel-job}}
Here is an example of an MPI job that uses 4 nodes with 4 cores each, running one process per core (16 processes total).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}N my\PYGZus{}job}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l walltime=10:00:00}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=4:ppn=4}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}q tem}

module load mpi/gcc/openmpi/1.8.8
\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
mpirun \PYGZhy{}machinefile \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE} ./a.out
\end{sphinxVerbatim}


\subsubsection{\sphinxstylestrong{Parallel job with MPI and OpenMP}}
\label{\detokenize{guide:parallel-job-with-mpi-and-openmp}}
This example is a hybrid MPI/OpenMP job. It runs one MPI process per node with 28 threads per process. The assumption here is that the code was written to support multi-level parallelism.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}N my\PYGZus{}job}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l walltime=20:00:00}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=4:ppn=28}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}q tem}

module load mpi/gcc/openmpi/1.8.8
\PYG{n+nb}{export} \PYG{n+nv}{OMP\PYGZus{}NUM\PYGZus{}THREADS}\PYG{o}{=}\PYG{l+m}{28}
\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
mpirun \PYGZhy{}\PYGZhy{}bynode \PYGZhy{}machinefile \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE} ./a.out
\end{sphinxVerbatim}


\subsection{Job submission}
\label{\detokenize{guide:job-submission}}
myscript.job : the script file name of a PBS batch job

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} qsub myscript.job
\end{sphinxVerbatim}

In response to this command you’ll see a line with your job ID:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m}{123456}.tem\PYGZhy{}ce.sdfarm.kr
\end{sphinxVerbatim}


\subsection{Monitoring and managing your jobs}
\label{\detokenize{guide:monitoring-and-managing-your-jobs}}

\subsubsection{\sphinxstylestrong{Status of queued jobs}}
\label{\detokenize{guide:status-of-queued-jobs}}\begin{itemize}
\item {} 
qstat

\end{itemize}

Use the qstat command to check the status of your jobs. You can see whether your job is queued or running, along with information about requested resources. If the job is running you can see elapsed time and resources used.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} By itself, qstat lists all jobs in the system:}
\PYGZdl{}\PYGZgt{} qstat

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} To list all the jobs belonging to a particular user:}
\PYGZdl{}\PYGZgt{} qstat \PYGZhy{}u tem\PYGZus{}user

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} To list the status of a particular job, in standard or alternate format:}
\PYGZdl{}\PYGZgt{} qstat \PYG{l+m}{123456}
\PYGZdl{}\PYGZgt{} qstat \PYGZhy{}a \PYG{l+m}{123456}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} To get all the details about a particular job (full status):}
\PYGZdl{}\PYGZgt{} qstat \PYGZhy{}f \PYG{l+m}{123456}
\end{sphinxVerbatim}


\subsubsection{\sphinxstylestrong{Managing your jobs}}
\label{\detokenize{guide:managing-your-jobs}}\begin{itemize}
\item {} 
Deleting (canceling) a job

\end{itemize}

Situations may arise in which you want to delete one of your jobs from the PBS queue. Perhaps you set the resource limits incorrectly, neglected to copy an input file, or had incorrect or missing commands in the batch file. Or maybe the program is taking too long to run (infinite loop). The PBS command to delete a batch job is qdel. It applies to both queued and running jobs.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} qdel \PYG{l+m}{123456}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Altering a queued job

\end{itemize}

You can alter certain attributes of your job while it’s in the queue using the qalter command. This can be useful if you want to make a change without losing your place in the queue. You cannot make any alterations to the executable portion of the script, nor can you make any changes after the job starts running.
The options argument consists of one or more PBS directives in the form of command-line options. For example, to change the walltime limit on job 123456 to 5 hours and have email sent when the job ends (only):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} The syntax is: qalter [options ...] jobid}
\PYGZdl{}\PYGZgt{} qalter \PYGZhy{}l \PYG{n+nv}{walltime}\PYG{o}{=}\PYG{l+m}{5}:00:00 \PYGZhy{}m e \PYG{l+m}{123456}
\end{sphinxVerbatim}


\chapter{Batch Queues}
\label{\detokenize{queue:batch-queues}}\label{\detokenize{queue::doc}}

\section{Batch queue list}
\label{\detokenize{queue:batch-queue-list}}
TEM farm provides multiple batch queues with different characteristics to users who submit jobs to analyze large-scale Cryo-EM data.
A batch queue means a logical set of CPU and GPU computing resources.
Users interact with a specific queue to manange their own jobs.
Within each queue, submitted jobs are executed in order (First-in-first-out).
Note that multiple jobs requiring CPU and/or GPU resources can be executed concurrently if there are enough available resources in the queue.

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.6]{{queues-description}.jpg}\hspace*{\fill}}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{4}{\X{1}{4}|}}
\hline

Category
&
Queue Name
&
Assigned Computing Resources
&
Remarks
\\
\hline\sphinxmultirow{3}{5}{%
\begin{varwidth}[t]{\sphinxcolwidth{1}{4}}
Dedicated
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
}%
&
\sphinxstylestrong{q01}
&\begin{itemize}
\item {} 
tem-wn{[}1001-1003{]}.sdfarm.kr (28 cores and 192GB memory per node)

\item {} 
tem-gpu01.sdfarm.kr (28 cores, 2 P100 GPGPUs and 384GB memory)

\end{itemize}
&\sphinxmultirow{3}{8}{%
\begin{varwidth}[t]{\sphinxcolwidth{1}{4}}
\begin{itemize}
\item {} 
USER/GROUP Access Control

\end{itemize}
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
}%
\\
\cline{2-3}\sphinxtablestrut{5}&
\sphinxstylestrong{q02}
&\begin{itemize}
\item {} 
tem-wn{[}1004-1006{]}.sdfarm.kr (28 cores and 192GB memory per node)

\item {} 
tem-gpu02.sdfarm.kr (28 cores, 2 P100 GPGPUs and 384 GB memory)

\end{itemize}
&\sphinxtablestrut{8}\\
\cline{2-3}\sphinxtablestrut{5}&
\sphinxstylestrong{q03}
&\begin{itemize}
\item {} 
tem-wn{[}1007-1009{]}.sdfarm.kr (28 cores and 192GB memory per node)

\item {} 
tem-gpu03.sdfarm.kr (28 cores, 2 P100 GPGPUs and 384 GB memory)

\end{itemize}
&\sphinxtablestrut{8}\\
\hline
Shared
&
\sphinxstylestrong{sharedq}
(default)
&\begin{itemize}
\item {} 
tem-wn{[}1010-1011{]}.sdfarm.kr

\end{itemize}
&\begin{itemize}
\item {} 
112 logical CPU cores

\item {} 
hyperthreading(H/T) enabled

\end{itemize}
\\
\hline\sphinxmultirow{2}{17}{%
\begin{varwidth}[t]{\sphinxcolwidth{1}{4}}
Experimental
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
}%
&
\sphinxstylestrong{exp01}
&\begin{itemize}
\item {} 
tem-gpu04.sdfarm.kr (48 cores, 128GB memory and 2 P40 GPGPUs)

\end{itemize}
&\begin{itemize}
\item {} 
logical CPU cores, H/T enabled

\end{itemize}
\\
\cline{2-4}\sphinxtablestrut{17}&
\sphinxstylestrong{exp02}
&\begin{itemize}
\item {} 
tem-gpu05.sdfarm.kr (48 cores, 128GB memory and 2 P40 GPGPUs)

\end{itemize}
&\begin{itemize}
\item {} 
logical CPU cores, H/T enabled

\end{itemize}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\section{Time schedule for queue assignment}
\label{\detokenize{queue:time-schedule-for-queue-assignment}}



\chapter{Relion}
\label{\detokenize{relion:relion}}\label{\detokenize{relion::doc}}
RELION (for REgularised LIkelihood OptimisatioN, pronounce rely-on) is a stand-alone computer program that employs an empirical Bayesian approach to refinement of (multiple) 3D reconstructions or 2D class averages in electron cryo-microscopy (cryo-EM). (from Relion official site \sphinxurl{https://www3.mrc-lmb.cam.ac.uk/relion/index.php?title=Main\_Page})


\section{Executing Relion GUI tools}
\label{\detokenize{relion:executing-relion-gui-tools}}

\subsection{How to start Relion data analysis tool}
\label{\detokenize{relion:how-to-start-relion-data-analysis-tool}}\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
You can find out relion applications’ environment module path by listing all the module available on TEM service farm

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module avail

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /tem/home/tem/Modules/Modules/versions \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{l+m}{3}.2.10

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /tem/home/tem/Modules/Modules/default/modulefiles \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
apps/gcc/4.4.7/cistem/1.0.0     cuda/9.1
apps/gcc/4.4.7/relion/cpu/3.0.7 modules
apps/gcc/4.4.7/relion/gpu/3.0.7 mpi/gcc/openmpi/1.8.8
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
Check the module details for the specific relion version (e.g., Relion v3.0.7 with GPGPU support or Relion v3.0.7 with CPU cores support only)

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module show apps/gcc/4.4.7/relion/gpu/3.0.7

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
/tem/home/tem/Modules/Modules/default/modulefiles/apps/gcc/4.4.7/relion/gpu/3.0.7:

module\PYGZhy{}whatis    Setups \PYG{l+s+sb}{{}`}relion\PYGZhy{}3.0.7\PYG{l+s+s1}{\PYGZsq{} environment variables}
\PYG{l+s+s1}{module           load mpi/gcc/openmpi/1.8.8}
\PYG{l+s+s1}{module           load cuda/9.1}
\PYG{l+s+s1}{setenv           relion\PYGZus{}version 3.0.7}
\PYG{l+s+s1}{prepend\PYGZhy{}path     PATH /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/gpu/bin}
\PYG{l+s+s1}{prepend\PYGZhy{}path     LD\PYGZus{}LIBRARY\PYGZus{}PATH /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/gpu/lib}
\PYG{l+s+s1}{setenv           LANG en\PYGZus{}US.UTF\PYGZhy{}8}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QUEUE\PYGZus{}NAME tem}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}COMMAND qsub}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}TEMPLATE /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/gpu/bin/qsub\PYGZhy{}relion3\PYGZhy{}gpu.bash}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA\PYGZus{}COUNT 3}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1 Number of Nodes}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA2 Number of processes per each node}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA3 Number of GPUs per node}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1\PYGZus{}DEFAULT 1}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA2\PYGZus{}DEFAULT 3}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA3\PYGZus{}DEFAULT 2}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}CTFFIND\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/ctffind\PYGZhy{}4.1.13/bin/ctffind}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}GCTF\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/Gctf\PYGZus{}v1.18\PYGZus{}b2/bin/Gctf\PYGZus{}v1.18\PYGZus{}b2\PYGZus{}sm60\PYGZus{}cu9.1}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}RESMAP\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/ResMap\PYGZhy{}1.1.4/ResMap\PYGZhy{}1.1.4\PYGZhy{}linux64}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}MOTIONCOR2\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/MotionCor2/MotionCor2\PYGZus{}Cuda9.1\PYGZus{}v1.0.5}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}UNBLUR\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/unblur\PYGZus{}1.0.2/bin/unblur\PYGZus{}openmp\PYGZus{}7\PYGZus{}17\PYGZus{}15.exe}
\PYG{l+s+s1}{setenv           RELION\PYGZus{}SUMMOVIE\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/summovie\PYGZus{}1.0.2/bin/sum\PYGZus{}movie\PYGZus{}openmp\PYGZus{}7\PYGZus{}17\PYGZus{}15.exe}
\PYG{l+s+s1}{conflict         apps/gcc/4.4.7/relion}
\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}

\PYG{l+s+s1}{or}

\PYG{l+s+s1}{\PYGZdl{}\PYGZgt{} module show apps/gcc/4.4.7/relion/cpu/3.0.7}

\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{l+s+s1}{/tem/home/tem/Modules/Modules/default/modulefiles/apps/gcc/4.4.7/relion/cpu/3.0.7:}

\PYG{l+s+s1}{module\PYGZhy{}whatis    Setups {}`relion\PYGZhy{}3.0.7\PYGZsq{}} environment variables
module           load mpi/gcc/openmpi/1.8.8
setenv           relion\PYGZus{}version \PYG{l+m}{3}.0.7
prepend\PYGZhy{}path     PATH /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/cpu/bin
prepend\PYGZhy{}path     LD\PYGZus{}LIBRARY\PYGZus{}PATH /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/cpu/lib
setenv           LANG en\PYGZus{}US.UTF\PYGZhy{}8
setenv           RELION\PYGZus{}QUEUE\PYGZus{}USE yes
setenv           RELION\PYGZus{}QUEUE\PYGZus{}NAME own\PYGZus{}queue\PYGZus{}name
setenv           RELION\PYGZus{}QSUB\PYGZus{}COMMAND qsub
setenv           RELION\PYGZus{}QSUB\PYGZus{}TEMPLATE /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/cpu/bin/qsub\PYGZhy{}relion3\PYGZhy{}cpu.bash
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA\PYGZus{}COUNT \PYG{l+m}{2}
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1 Number of Nodes
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA2 Number of processes per each node
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1\PYGZus{}DEFAULT \PYG{l+m}{2}
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA2\PYGZus{}DEFAULT \PYG{l+m}{16}
setenv           RELION\PYGZus{}CTFFIND\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/ctffind\PYGZhy{}4.1.13/bin/ctffind
setenv           RELION\PYGZus{}GCTF\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/Gctf\PYGZus{}v1.18\PYGZus{}b2/bin/Gctf\PYGZus{}v1.18\PYGZus{}b2\PYGZus{}sm60\PYGZus{}cu9.1
setenv           RELION\PYGZus{}RESMAP\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/ResMap\PYGZhy{}1.1.4/ResMap\PYGZhy{}1.1.4\PYGZhy{}linux64
setenv           RELION\PYGZus{}MOTIONCOR2\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/MotionCor2/MotionCor2\PYGZus{}Cuda9.1\PYGZus{}v1.0.5
setenv           RELION\PYGZus{}UNBLUR\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/unblur\PYGZus{}1.0.2/bin/unblur\PYGZus{}openmp\PYGZus{}7\PYGZus{}17\PYGZus{}15.exe
setenv           RELION\PYGZus{}SUMMOVIE\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/summovie\PYGZus{}1.0.2/bin/sum\PYGZus{}movie\PYGZus{}openmp\PYGZus{}7\PYGZus{}17\PYGZus{}15.exe
conflict         apps/gcc/4.4.7/relion
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Load the environment module for the version of relion application which you want to execute. As the module specified is loaded, all the modules with dependency are also loaded (you can check these modules with “module list” command)

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module load apps/gcc/4.4.7/relion/gpu/3.0.7
\PYGZdl{}\PYGZgt{} module list
Currently Loaded Modulefiles:
  \PYG{l+m}{1}\PYG{o}{)} mpi/gcc/openmpi/1.8.8             \PYG{l+m}{2}\PYG{o}{)} cuda/9.1                          \PYG{l+m}{3}\PYG{o}{)} apps/gcc/4.4.7/relion/gpu/3.0.7
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Check the relion application binary path

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} which relion
/tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/gpu/bin/relion
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
Execute the relion application (we assume that X11 forwarding is enabled)

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} relion
\end{sphinxVerbatim}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{relion-screenshot}.png}\hspace*{\fill}}


\section{PBS Strings used in Relion}
\label{\detokenize{relion:pbs-strings-used-in-relion}}

\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{torque\_strings\_of\_relion}\label{\detokenize{relion:id2}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

String
&
Variable type
&
Description
\\
\hline
\sphinxstylestrong{XXXcommandXXX}
&
string
&
relion command + arguments
\\
\hline
\sphinxstylestrong{XXXqueueXXX}
&
string
&
Name of the queue to submit job to
\\
\hline
\sphinxstylestrong{XXXmpinodesXXX}
&
integer
&
The number of MPI processes to use
\\
\hline
\sphinxstylestrong{XXXthreadsXXX}
&
integer
&
The number of threads to use on each MPI process
\\
\hline
\sphinxstylestrong{XXXcoresXXX}
&
integer
&
The number of MPI processes times the number of threads
\\
\hline
\sphinxstylestrong{XXXdedicatedXXX}
&
integer
&
The minimum number of cores on each node
(use this to fill entire nodes)
\\
\hline
\sphinxstylestrong{XXXnodesXXX}
&
integer
&
The total number of nodes to be requested
\\
\hline
\sphinxstylestrong{XXXextra1XXX}
&
string
&
Installation-specific
\\
\hline
\sphinxstylestrong{XXXextra2XXX}
&
string
&
Installation-specific
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Relion, by default, does not use the XXXextra1XXX, XXXextra2XXX, … variables.
They provide additional flexibility for queueing systems (like Torque) that require additional variables.
They may be activated by first setting RELION\_QSUB\_EXTRA\_COUNT to the number of fields you need (e.g. 3) and then setting the RELION\_QSUB\_EXTRA1, RELION\_QSUB\_EXTRA2, RELION\_QSUB\_EXTRA3 … environment variables, respectively.
This will result in extra input fields in the GUI, with the label text being equal to the value of the environment variable. Likewise, their default values (upon starting the GUI) can be set through environment variables RELION\_QSUB\_EXTRA1\_DEFAULT, RELION\_QSUB\_EXTRA2\_DEFAULT, etc and their help messages can be set through environmental variables RELION\_QSUB\_EXTRA1\_HELP, RELION\_QSUB\_EXTRA2\_HELP and so on.


\section{Using CPU cluster (apps/gcc/4.4.7/relion/cpu/3.0.7)}
\label{\detokenize{relion:using-cpu-cluster-apps-gcc-4-4-7-relion-cpu-3-0-7}}

\subsection{RELION\_QSUB\_TEMPLATE variable}
\label{\detokenize{relion:relion-qsub-template-variable}}
Relion defines a lot of environment variables that can be used to execute different types of subtasks in the analysis workflows. Among these, “RELION\_QSUB\_TEMPLATE” describes the location of a proper batch job script template to submit jobs to the farm.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}\PYG{k}{for} relion \PYG{l+m}{3}.0.7\PYG{o}{)} RELION\PYGZus{}QSUB\PYGZus{}TEMPLATE /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/cpu/bin/qsub\PYGZhy{}relion3\PYGZhy{}cpu.bash
\end{sphinxVerbatim}

For the use of CPU cluster nodes, we have set the RELION\_QSUB\_EXTRA\_COUNT to 2. Two extra options describe “Number of Nodes” and “Number of processes per each node”, respectively. These values can be referred by XXXextra1, XXXextra2XXX in the following batch job script template.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA\PYGZus{}COUNT \PYG{l+m}{2}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA1 \PYG{l+s+s2}{\PYGZdq{}Number of Nodes\PYGZdq{}}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA2 \PYG{l+s+s2}{\PYGZdq{}Number of processes per each node\PYGZdq{}}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA1\PYGZus{}DEFAULT \PYG{l+m}{2}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA2\PYGZus{}DEFAULT \PYG{l+m}{16}
\end{sphinxVerbatim}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.7]{{relion-cpu}.jpg}\hspace*{\fill}}

As shown in above figure, you can browse and select \sphinxstylestrong{“standard submission script”} as the location of RELION\_QSUB\_TEMPLATE for relion 3.0.7 (i.e., /tem/home/tem/\_Applications/relion-3.0.7/cpu/bin/qsub-relion3-cpu.bash or its own your copy), and give \sphinxstylestrong{“Number of Nodes”} and \sphinxstylestrong{“Number of processes per each node”} values instead of default ones to submit a job to Torque based TEM farm.
\sphinxstylestrong{(NOTE : you MUST use your OWN QUEUEe for “Queue name” and correct “number of MPI procs” which is generally total number of processes (number of nodes x number of processes per each node))}


\subsection{Job script template (for CPU use)}
\label{\detokenize{relion:job-script-template-for-cpu-use}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Inherit all current environment variables}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}V}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Job name}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}N XXXnameXXX}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Queue name}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}q XXXqueueXXX}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} CPU cluster use : Specify the number of nodes (XXXextra1XXX) and the number of processes per each node (XXXextra2XXX)}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=XXXextra1XXX:ppn=XXXextra2XXX:XXXqueueXXX}

\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}o \PYGZdl{}\PYGZob{}PBS\PYGZus{}JOBNAME\PYGZcb{}/run.out}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}e \PYGZdl{}\PYGZob{}PBS\PYGZus{}JOBNAME\PYGZcb{}/run.err}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Print Environment Variables}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{n+nb}{echo} \PYGZhy{}n \PYG{l+s+s1}{\PYGZsq{}Job is running on node \PYGZsq{}}\PYG{p}{;} cat \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{n+nb}{echo} PBS: qsub is running on \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}HOST}
\PYG{n+nb}{echo} PBS: originating queue is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}QUEUE}
\PYG{n+nb}{echo} PBS: executing queue is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}QUEUE}
\PYG{n+nb}{echo} PBS: working directory is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
\PYG{n+nb}{echo} PBS: execution mode is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}ENVIRONMENT}
\PYG{n+nb}{echo} PBS: job identifier is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}JOBID}
\PYG{n+nb}{echo} PBS: job name is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}JOBNAME}
\PYG{n+nb}{echo} PBS: node file is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE}
\PYG{n+nb}{echo} PBS: current home directory is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}HOME}
\PYG{n+nb}{echo} PBS: \PYG{n+nv}{PATH} \PYG{o}{=} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}PATH}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{} Switch to the working directory;}
\PYG{n+nb}{cd} \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}O\PYGZus{}WORKDIR}\PYG{l+s+si}{\PYGZcb{}}/\PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}JOBNAME}\PYG{l+s+si}{\PYGZcb{}}
touch run.out
touch run.err
\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Run:}
module load apps/gcc/4.4.7/relion/cpu/3.0.7
mpirun \PYGZhy{}\PYGZhy{}prefix /tem/home/tem/\PYGZus{}SystemLibs/openmpi\PYGZhy{}1.8.8 \PYGZhy{}machinefile \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE} XXXcommandXXX

\PYG{n+nb}{echo} \PYG{l+s+s2}{\PYGZdq{}Done!\PYGZdq{}}
\end{sphinxVerbatim}


\section{Using GPGPU cluster (apps/gcc/4.4.7/relion/gpu/3.0.7)}
\label{\detokenize{relion:using-gpgpu-cluster-apps-gcc-4-4-7-relion-gpu-3-0-7}}

\subsection{RELION\_QSUB\_TEMPLATE variable}
\label{\detokenize{relion:id1}}
Relion defines a lot of environment variables that can be used to execute different types of subtasks in the analysis workflows. Among these, “RELION\_QSUB\_TEMPLATE” describes the location of a proper batch job script to submit jobs to the farm.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}\PYG{k}{for} relion \PYG{l+m}{3}.0.7 w/ GPU support\PYG{o}{)} RELION\PYGZus{}QSUB\PYGZus{}TEMPLATE /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/gpu/bin/qsub\PYGZhy{}relion3\PYGZhy{}gpu.bash
\end{sphinxVerbatim}

Unlike CPU cluster use case, we have set the RELION\_QSUB\_EXTRA\_COUNT to 3 for the use of GPGPU cluster,
where each extra option describes “Number of Nodes”, “Number of processes per each node”, and “Number of GPUs per node”, respectively. All these values can be accessed by XXXextra1, XXXextra2XXX, XXXextra3XXX in the batch job script template.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA\PYGZus{}COUNT \PYG{l+m}{3}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA1 \PYG{l+s+s2}{\PYGZdq{}Number of Nodes\PYGZdq{}}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA2 \PYG{l+s+s2}{\PYGZdq{}Number of processes per each node\PYGZdq{}}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA3 \PYG{l+s+s2}{\PYGZdq{}Number of GPUs per node\PYGZdq{}}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA1\PYGZus{}DEFAULT \PYG{l+m}{1}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA2\PYGZus{}DEFAULT \PYG{l+m}{3}
setenv RELION\PYGZus{}QSUB\PYGZus{}EXTRA3\PYGZus{}DEFAULT \PYG{l+m}{2}
\end{sphinxVerbatim}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.7]{{relion-script-description}.png}\hspace*{\fill}}


\subsection{Job script template (for GPGPU use)}
\label{\detokenize{relion:job-script-template-for-gpgpu-use}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Inherit all current environment variables}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}V}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Job name}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}N XXXnameXXX}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Queue name}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}q XXXqueueXXX}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} GPU use : Specify the number of nodes (XXXextra1XXX), the number of processes per each node (XXXextra2XXX), and the number of GPGPUs per node (XXXextra3XXX)}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=XXXextra1XXX:ppn=XXXextra2XXX:gpus=XXXextra3XXX:XXXqueueXXX}

\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}o \PYGZdl{}\PYGZob{}PBS\PYGZus{}JOBNAME\PYGZcb{}/run.out}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}e \PYGZdl{}\PYGZob{}PBS\PYGZus{}JOBNAME\PYGZcb{}/run.err}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Print Environment Variables}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{n+nb}{echo} \PYGZhy{}n \PYG{l+s+s1}{\PYGZsq{}Job is running on node \PYGZsq{}}\PYG{p}{;} cat \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{n+nb}{echo} PBS: qsub is running on \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}HOST}
\PYG{n+nb}{echo} PBS: originating queue is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}QUEUE}
\PYG{n+nb}{echo} PBS: executing queue is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}QUEUE}
\PYG{n+nb}{echo} PBS: working directory is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
\PYG{n+nb}{echo} PBS: execution mode is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}ENVIRONMENT}
\PYG{n+nb}{echo} PBS: job identifier is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}JOBID}
\PYG{n+nb}{echo} PBS: job name is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}JOBNAME}
\PYG{n+nb}{echo} PBS: node file is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE}
\PYG{n+nb}{echo} PBS: current home directory is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}HOME}
\PYG{n+nb}{echo} PBS: \PYG{n+nv}{PATH} \PYG{o}{=} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}PATH}
\PYG{n+nb}{echo} PBS: \PYG{n+nv}{PBS\PYGZus{}GPUFILE}\PYG{o}{=}\PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}GPUFILE}
\PYG{n+nb}{echo} PBS: \PYG{n+nv}{CUDA\PYGZus{}VISIBLE\PYGZus{}DEVICES}\PYG{o}{=}\PYG{n+nv}{\PYGZdl{}CUDA\PYGZus{}VISIBLE\PYGZus{}DEVICES}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{} Switch to the working directory;}
\PYG{n+nb}{cd} \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}O\PYGZus{}WORKDIR}\PYG{l+s+si}{\PYGZcb{}}/\PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}JOBNAME}\PYG{l+s+si}{\PYGZcb{}}
touch run.out
touch run.err
\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Run:}
module load apps/gcc/4.4.7/relion/gpu/3.0.7
mpirun \PYGZhy{}\PYGZhy{}prefix /tem/home/tem/openmpi\PYGZhy{}1.8.8 \PYGZhy{}machinefile \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE} XXXcommandXXX

\PYG{n+nb}{echo} \PYG{l+s+s2}{\PYGZdq{}Done!\PYGZdq{}}
\end{sphinxVerbatim}


\subsection{Specifying which GPUs to use}
\label{\detokenize{relion:specifying-which-gpus-to-use}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.7]{{relion-gpu-node-allocation}.png}\hspace*{\fill}}

Here, we describe more advanced syntax for restricting RELION processes to certain GPUs on multi-GPU setups. You can use an argument to the \textendash{}gpu option to provide a list of device-indices. The syntax is then to delimit ranks with colons {[}:{]}, and threads by commas {[},{]}. Any GPU indices provided is taken to be a list which is repeated if shorter than the total number of GPUs. By extension, the following rules applies

If a GPU id is specified more than once for a single mpi-rank, that GPU will be assigned proprotionally more of the threads of that rank.
If no colons are used (i.e. GPUs are only specified for a single rank), then the GPUs specified, apply to all ranks.
If GPUs are specified for more than one rank but not for all ranks, the unrestricted ranks are assigned the same GPUs as the restricted ranks, by a modulo rule.
For example, if you would only want to use two of the four GPUs for all mpi-ranks, because you want to leave another two free for a different user/job, then (by the above rule 2) you can specify

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mpirun \PYGZhy{}n \PYG{l+m}{3} ‘which relion\PYGZus{}refine\PYGZus{}mpi‘ \PYGZhy{}\PYGZhy{}gpu \PYG{l+m}{2}:3
slave \PYG{l+m}{1} is told to use GPU2. slave \PYG{l+m}{2} is told to use GPU3.
\end{sphinxVerbatim}

If you want an even spread over ALL GPUs, then you should not specify selection indices, as RELION will handle this itself. On your hypothetical 4-GPU machine, you would simply say

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mpirun \PYGZhy{}n \PYG{l+m}{3} ‘which relion\PYGZus{}refine\PYGZus{}mpi‘ \PYGZhy{}\PYGZhy{}gpu
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} slave 1 will use GPU0 and GPU1 for its threads. slave 2 will use GPU2 and GPU3 for its threads}
\end{sphinxVerbatim}

One can also schedule individual threads from MPI processes on the GPUs. This would be most useful when available RAM would be a limitation. Then one could for example run 3 MPI processes, each of which spawn a number of threads on two of the cards each, as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mpirun \PYGZhy{}n \PYG{l+m}{3} ‘which relion\PYGZus{}refine\PYGZus{}mpi‘ \PYGZhy{}\PYGZhy{}j \PYG{l+m}{4} \PYGZhy{}\PYGZhy{}gpu \PYG{l+m}{0},1,1,2:3
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} slave 1 is told to put thread 1 on GPU0, threads 2 and 3 on GPU1, and thread 4 on GPU2.  slave 2 is told to put all 4 threads on GPU3.}
\end{sphinxVerbatim}

Finally, for completeness, the following is a more complex example to illustrate the full functionality of the GPU-device specification options.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mpirun \PYGZhy{}n \PYG{l+m}{4} ... \PYGZhy{}j \PYG{l+m}{3} \PYGZhy{}\PYGZhy{}gpu \PYG{l+m}{2}:2:1,3
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} slave 1 w/ 3 threads on GPU2, slave 2 w/ 3 threads on GPU2, slave 3 distributes 3 threads as evenly as possible across GPU1 and GPU3.}
\end{sphinxVerbatim}

For more information, please refer to Relion Benchmarks and computer hardware (\sphinxurl{https://www3.mrc-lmb.cam.ac.uk/relion/index.php/Benchmarks\_\%26\_computer\_hardware})


\section{Executing CPU/GPU jobs in Relion}
\label{\detokenize{relion:executing-cpu-gpu-jobs-in-relion}}
Basically, with GPU-enabled Relion GUI, users can execute GPU-accelerated built-in subprograms, for examples :
\begin{itemize}
\item {} 
\sphinxstylestrong{refine, refine\_mpi} (only the slaves, not the master)

\item {} 
\sphinxstylestrong{autopick, autopick\_mpi} (master and slaves)

\end{itemize}

and 3rd-party GPU-accelerated programs, for examples :
\begin{itemize}
\item {} 
\sphinxstylestrong{Gctf} (/tem/home/tem/\_Applications/Gctf\_v1.18\_b2/bin/Gctf\_v1.18\_b2\_sm60\_cu9.1)

\item {} 
\sphinxstylestrong{MotionCor2} (/tem/home/tem/\_Applications/MotionCor2/MotionCor2\_Cuda9.1\_v1.0.5)

\end{itemize}

However, the GPU-enabled Relion also includes other built-in or 3rd-party CPU-only subprograms which follows :
\begin{itemize}
\item {} 
\sphinxstylestrong{MotionCor2-like alignment algorithm} (by Takanori Nakane)

\item {} 
\sphinxstylestrong{CTFFind 4.1} (/tem/home/tem/\_Applications/ctffind-4.1.13/bin/ctffind)

\item {} 
\sphinxstylestrong{autopick} (built-in)

\item {} 
\sphinxstylestrong{particle extraction} (built-in)

\item {} 
\sphinxstylestrong{particle sorting} (built-in)

\item {} 
\sphinxstylestrong{subset selection} (built-in)

\item {} 
\sphinxstylestrong{2D classification} (built-in)

\item {} 
\sphinxstylestrong{3D classification} (built-in)

\item {} 
\sphinxstylestrong{3D refinement, 3D multi-body} (built-in)

\item {} 
\sphinxstylestrong{CTF refinement} (built-in)

\item {} 
\sphinxstylestrong{Particle substraction, etc.} (built-in)

\end{itemize}

So, for users convenience, we have deployed another Relion application with more generic computational resources requirements (GPU and/or CPU).


\subsection{Module path}
\label{\detokenize{relion:module-path}}\begin{itemize}
\item {} 
apps/gcc/4.4.7/relion/gpu/3.0.7p

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module avail

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /tem/home/tem/Modules/Modules/versions \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
3.2.10

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /tem/home/tem/Modules/Modules/default/modulefiles \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
apps/gcc/4.4.7/cistem/1.0.0      cuda/9.1
apps/gcc/4.4.7/relion/cpu/3.0.7  modules
apps/gcc/4.4.7/relion/gpu/3.0.7  mpi/gcc/openmpi/1.8.8
apps/gcc/4.4.7/relion/gpu/3.0.7p

\PYGZdl{}\PYGZgt{} module show apps/gcc/4.4.7/relion/gpu/3.0.7p

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
/tem/home/tem/Modules/Modules/default/modulefiles/apps/gcc/4.4.7/relion/gpu/3.0.7p:

module\PYGZhy{}whatis    Setups {}`relion\PYGZhy{}3.0.7\PYGZsq{} environment variables
module           load mpi/gcc/openmpi/1.8.8
module           load cuda/9.1
setenv           relion\PYGZus{}version 3.0.7
prepend\PYGZhy{}path     PATH /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/test/bin
prepend\PYGZhy{}path     LD\PYGZus{}LIBRARY\PYGZus{}PATH /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/test/lib
setenv           LANG en\PYGZus{}US.UTF\PYGZhy{}8
setenv           RELION\PYGZus{}QUEUE\PYGZus{}USE yes
setenv           RELION\PYGZus{}QUEUE\PYGZus{}NAME own\PYGZus{}queue\PYGZus{}name
setenv           RELION\PYGZus{}QSUB\PYGZus{}COMMAND qsub
setenv           RELION\PYGZus{}QSUB\PYGZus{}TEMPLATE /tem/home/tem/\PYGZus{}Applications/relion\PYGZhy{}3.0.7/test/bin/qsub\PYGZhy{}relion3\PYGZhy{}gpu.bash
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA\PYGZus{}COUNT 1
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1 Resource Requirements
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1\PYGZus{}DEFAULT nodes=1:ppn=3:gpus=2
setenv           RELION\PYGZus{}QSUB\PYGZus{}EXTRA1\PYGZus{}HELP For the use of GPUs, nodes=\PYGZlt{}\PYGZsh{}of nodes\PYGZgt{}:ppn=\PYGZlt{}\PYGZsh{} of processes per n\PYGZsh{} of GPUs per node\PYGZgt{}. For the use of CPU cores, nodes=\PYGZlt{}\PYGZsh{}of nodes\PYGZgt{}:ppn=\PYGZlt{}\PYGZsh{} of processes per node\PYGZgt{}
setenv           RELION\PYGZus{}CTFFIND\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/ctffind\PYGZhy{}4.1.13/bin/ctffind
setenv           RELION\PYGZus{}GCTF\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/Gctf\PYGZus{}v1.18\PYGZus{}b2/bin/Gctf\PYGZus{}v1.18\PYGZus{}b2\PYGZus{}sm60\PYGZus{}cu9.1
setenv           RELION\PYGZus{}RESMAP\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/ResMap\PYGZhy{}1.1.4/ResMap\PYGZhy{}1.1.4\PYGZhy{}linux64
setenv           RELION\PYGZus{}MOTIONCOR2\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/MotionCor2/MotionCor2\PYGZus{}Cuda9.1\PYGZus{}v1.0.5
setenv           RELION\PYGZus{}UNBLUR\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/unblur\PYGZus{}1.0.2/bin/unblur\PYGZus{}openmp\PYGZus{}7\PYGZus{}17\PYGZus{}15.exe
setenv           RELION\PYGZus{}SUMMOVIE\PYGZus{}EXECUTABLE /tem/home/tem/\PYGZus{}Applications/summovie\PYGZus{}1.0.2/bin/sum\PYGZus{}movie\PYGZus{}openmp\PYGZus{}7\PYGZus{}17\PYGZus{}15.exe
conflict         apps/gcc/4.4.7/relion
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

\PYGZdl{}\PYGZgt{} module load apps/gcc/4.4.7/relion/gpu/3.0.7p
\PYGZdl{}\PYGZgt{} module list
Currently Loaded Modulefiles:
  1) mpi/gcc/openmpi/1.8.8              2) cuda/9.1                           3) apps/gcc/4.4.7/relion/gpu/3.0.7p
\end{sphinxVerbatim}

Here, we have set the RELION\_QSUB\_EXTRA\_COUNT to 1 for the statement of more generic resource requirements (nodes, ppn, gpus) which denote “Number of Nodes”, “Number of processes per each node” and “Number of GPUs per node”, respectively.
\begin{itemize}
\item {} 
\sphinxstylestrong{nodes} : number of nodes required (default:1)

\item {} 
\sphinxstylestrong{ppn} : number of processes(cores) per node (default:3)

\item {} 
\sphinxstylestrong{gpus} : number of GPU devices per node (default:2)

\end{itemize}


\subsection{Job script template}
\label{\detokenize{relion:job-script-template}}\begin{itemize}
\item {} 
RELION\_QSUB\_TEMPLATE : /tem/home/tem/\_Applications/relion-3.0.7/test/bin/qsub-relion3-gpu.bash

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Inherit all current environment variables}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}V}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Job name}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}N XXXnameXXX}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Queue name}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}q XXXqueueXXX}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Resource requirements : XXXextra1XXX}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l XXXextra1XXX:XXXqueueXXX}

\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}o \PYGZdl{}\PYGZob{}PBS\PYGZus{}JOBNAME\PYGZcb{}/run.out}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}e \PYGZdl{}\PYGZob{}PBS\PYGZus{}JOBNAME\PYGZcb{}/run.err}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Print Environment Variables}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{n+nb}{echo} \PYGZhy{}n \PYG{l+s+s1}{\PYGZsq{}Job is running on node \PYGZsq{}}\PYG{p}{;} cat \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{n+nb}{echo} PBS: qsub is running on \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}HOST}
\PYG{n+nb}{echo} PBS: originating queue is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}QUEUE}
\PYG{n+nb}{echo} PBS: executing queue is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}QUEUE}
\PYG{n+nb}{echo} PBS: working directory is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
\PYG{n+nb}{echo} PBS: execution mode is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}ENVIRONMENT}
\PYG{n+nb}{echo} PBS: job identifier is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}JOBID}
\PYG{n+nb}{echo} PBS: job name is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}JOBNAME}
\PYG{n+nb}{echo} PBS: node file is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE}
\PYG{n+nb}{echo} PBS: current home directory is \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}HOME}
\PYG{n+nb}{echo} PBS: \PYG{n+nv}{PATH} \PYG{o}{=} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}PATH}
\PYG{n+nb}{echo} PBS: \PYG{n+nv}{PBS\PYGZus{}GPUFILE}\PYG{o}{=}\PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}GPUFILE}
\PYG{n+nb}{echo} PBS: \PYG{n+nv}{CUDA\PYGZus{}VISIBLE\PYGZus{}DEVICES}\PYG{o}{=}\PYG{n+nv}{\PYGZdl{}CUDA\PYGZus{}VISIBLE\PYGZus{}DEVICES}
\PYG{n+nb}{echo} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{} Switch to the working directory;}
\PYG{n+nb}{cd} \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}O\PYGZus{}WORKDIR}\PYG{l+s+si}{\PYGZcb{}}/\PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}JOBNAME}\PYG{l+s+si}{\PYGZcb{}}
touch run.out
touch run.err
\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Run:}
module load apps/gcc/4.4.7/relion/gpu/3.0.7p
mpirun \PYGZhy{}\PYGZhy{}prefix /tem/home/tem/openmpi\PYGZhy{}1.8.8 \PYGZhy{}machinefile \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}NODEFILE} XXXcommandXXX

\PYG{n+nb}{echo} \PYG{l+s+s2}{\PYGZdq{}Done!\PYGZdq{}}
\end{sphinxVerbatim}


\subsection{Examples}
\label{\detokenize{relion:examples}}

\subsubsection{Motion Correction}
\label{\detokenize{relion:motion-correction}}\begin{itemize}
\item {} 
\sphinxstylestrong{MotionCor2-like alignment algorithm} (CPU-only job, relion-own implementation)
\begin{itemize}
\item {} 
(Motion) Use RELION’s own implementation? : Yes

\item {} 
(Running) Number of MPI Procs : 84

\item {} 
(Running) Number of threads : 1

\item {} 
(Running) Queue name : \textless{}your own queue name\textgreater{} (e.g., q02)

\item {} 
(Running) Resource Requirements : nodes=3:ppn=28  (e.g., we assume the use of 3 nodes and all 28 cores each node)

\item {} 
(Running) Standard submission script : /tem/home/tem/\_Applications/relion-3.0.7/test/bin/qsub-relion3-gpu.bash

\end{itemize}

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{relion-motioncor1}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{relion-motioncor2}.png}\hspace*{\fill}}
\begin{itemize}
\item {} 
\sphinxstylestrong{MotionCor2} (GPU-accelerated job)
\begin{itemize}
\item {} 
(Motion) Use RELION’s own implementation? : No

\item {} 
(Motion) MOTIONCOR2 executable : /tem/home/tem/\_Applications/MotionCor2/MotionCor2\_Cuda9.1\_v1.0.5

\item {} 
(Running) Number of MPI Procs : 2

\item {} 
(Running) Number of threads : 1

\item {} 
(Running) Queue name : \textless{}your own queue name\textgreater{} (e.g., q02)

\item {} 
(Running) Resource Requirements : nodes=1:ppn=2:gpus=2  (e.g., we assume the use of 1 gpu node, 2 cpu cores  and 2 GPU devices)

\item {} 
(Running) Standard submission script : /tem/home/tem/\_Applications/relion-3.0.7/test/bin/qsub-relion3-gpu.bash

\end{itemize}

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{motioncor2-1}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{motioncor2-2}.png}\hspace*{\fill}}


\subsubsection{CTF Estimation}
\label{\detokenize{relion:ctf-estimation}}\begin{itemize}
\item {} 
\sphinxstylestrong{CTFFIND-4.1} (CPU-only job)
\begin{itemize}
\item {} 
(CTFFIND-4.1) Use CTFFIND-4.1? : Yes

\item {} 
(CTFFIND-4.1) CTFFIND-4.1 executable? : /tem/home/tem/\_Applications/ctffind-4.1.13/bin/ctffind

\item {} 
(Gctf) Use Gctf instead? : No

\item {} 
(Running) Number of MPI procs: 48

\item {} 
(Running) Submit to queue? : Yes

\item {} 
(Running) Queue name : \textless{}your own queue name\textgreater{} (e.g., q02)

\item {} 
(Running) Resource Requirements : nodes=3:ppn=16  (e.g., we assume the use of 3 nodes, 16 cpu cores per each node)

\item {} 
(Running) Standard submission script : /tem/home/tem/\_Applications/relion-3.0.7/test/bin/qsub-relion3-gpu.bash

\end{itemize}

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{ctffind-1}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{ctffind-2}.png}\hspace*{\fill}}
\begin{itemize}
\item {} 
\sphinxstylestrong{Gctf} (GPU-accelerated job)
\begin{itemize}
\item {} 
(CTFFIND-4.1) Use CTFFIND-4.1? : No

\item {} 
(Gctf) Use Gctf instead? : Yes

\item {} 
(Gctf) Gctf executable: /tem/home/tem/\_Applications/Gctf\_v1.18\_b2/bin/Gctf\_v1.18\_b2\_sm60\_cu9.1

\item {} 
(Gctf) Which GPUs to use: \textless{}empty\textgreater{} (i.e., relion automatically assigned available GPU devices to the MPI processes)

\item {} 
(Running) Number of MPI procs: 5 (1 master and 4 slave processes)

\item {} 
(Running) Submit to queue? : Yes

\item {} 
(Running) Queue name : \textless{}your own queue name\textgreater{} (e.g., q02)

\item {} 
(Running) Resource Requirements : nodes=1:ppn=5:gpus=2

\item {} 
(Running) Standard submission script : /tem/home/tem/\_Applications/relion-3.0.7/test/bin/qsub-relion3-gpu.bash

\end{itemize}

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{gctf-1}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{gctf-2}.png}\hspace*{\fill}}


\subsubsection{2D Classification}
\label{\detokenize{relion:d-classification}}\begin{itemize}
\item {} 
\sphinxstylestrong{relion\_refine\_mpi} (CPU-only job)
\begin{itemize}
\item {} 
(Compute) Use GPU acceleration? : No

\item {} 
(Running) Number of MPI procs: 112

\item {} 
(Running) Number of threads: 1

\item {} 
(Running) Submit to queue? : Yes

\item {} 
(Running) Queue name : \textless{}your own queue name\textgreater{} (e.g., q02)

\item {} 
(Running) Resource Requirements : nodes=4:ppn=28  (e.g., we assume the use of 4 nodes, 28 cpu cores per each node)

\item {} 
(Running) Standard submission script : /tem/home/tem/\_Applications/relion-3.0.7/test/bin/qsub-relion3-gpu.bash

\end{itemize}

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{2dclass-1}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{2dclass-2}.png}\hspace*{\fill}}
\begin{itemize}
\item {} 
\sphinxstylestrong{relion\_refine\_mpi} (GPU-accelerated job)
\begin{itemize}
\item {} 
(Compute) Use GPU acceleration? : Yes

\item {} 
(Compute) Which GPUs to use? : 0:1 (i.e., we will assign each slave process to GPU device index 0 and 1, respectively)

\item {} 
(Running) Number of MPI procs: 3 (1 master and 2 slave processes)

\item {} 
(Running) Number of threads: 1

\item {} 
(Running) Submit to queue? : Yes

\item {} 
(Running) Queue name : \textless{}your own queue name\textgreater{} (e.g., q02)

\item {} 
(Running) Resource Requirements : nodes=1:ppn=3:gpus=2

\item {} 
(Running) Standard submission script : /tem/home/tem/\_Applications/relion-3.0.7/test/bin/qsub-relion3-gpu.bash

\end{itemize}

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{2dclassgpu-1}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{2dclassgpu-2}.png}\hspace*{\fill}}


\chapter{cisTEM}
\label{\detokenize{cisTEM:cistem}}\label{\detokenize{cisTEM::doc}}
cisTEM is user-friendly software to process cryo-EM images of macromolecular complexes and obtain high-resolution 3D reconstructions from them. It comprises a number of tools to process image data including movies, micrographs and stacks of single-particle images, implementing a complete “pipeline” of processing steps to obtain high-resolution single-particle reconstructions. (from cisTEM official site \sphinxurl{https://cistem.org})


\section{Executing cisTEM}
\label{\detokenize{cisTEM:executing-cistem}}

\subsection{How to start cisTEM data analysis tool}
\label{\detokenize{cisTEM:how-to-start-cistem-data-analysis-tool}}\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
You can find out cisTEM applications’ environment module path by listing all the module available on TEM service farm.

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module avail

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /tem/home/tem/Modules/Modules/versions \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{l+m}{3}.2.10

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /tem/home/tem/Modules/Modules/default/modulefiles \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
apps/gcc/4.4.7/cistem/1.0.0     cuda/9.1
apps/gcc/4.4.7/relion/cpu/3.0.7 modules
apps/gcc/4.4.7/relion/gpu/3.0.7 mpi/gcc/openmpi/1.8.8
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
Check the module details for cisTEM application

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module show apps/gcc/4.4.7/cistem/1.0.0

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
/tem/home/tem/Modules/Modules/default/modulefiles/apps/gcc/4.4.7/cistem/1.0.0:

module\PYGZhy{}whatis    Setups {}`cistem\PYGZhy{}1.0.0\PYGZsq{} environment variables
module           load mpi/gcc/openmpi/1.8.8
prepend\PYGZhy{}path     PATH /tem/home/tem/\PYGZus{}Applications/cistem\PYGZhy{}1.0.0\PYGZhy{}beta
conflict         apps/gcc/4.4.7/cistem
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Load the environment module for cisTEM  application which you want to execute. As the module specified is loaded, all the modules with dependency are also loaded (you can check these modules with “module list” command)

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} module load apps/gcc/4.4.7/cistem/1.0.0
\PYGZdl{}\PYGZgt{} module list
Currently Loaded Modulefiles:
  \PYG{l+m}{1}\PYG{o}{)} mpi/gcc/openmpi/1.8.8         \PYG{l+m}{2}\PYG{o}{)} apps/gcc/4.4.7/cistem/1.0.0
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Check the cisTEM application binary path

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} which cisTEM
/tem/home/tem/\PYGZus{}Applications/cistem\PYGZhy{}1.0.0\PYGZhy{}beta/cisTEM
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
Execute the cisTEM application (we assume that X11 forwarding is enabled)

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}\PYGZgt{} cisTEM
\end{sphinxVerbatim}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{cistem-screenshot-re}.png}\hspace*{\fill}}


\section{Run profiles for job submission}
\label{\detokenize{cisTEM:run-profiles-for-job-submission}}

\subsection{Profile templates}
\label{\detokenize{cisTEM:profile-templates}}
If you need cisTEM to work on multiple computing servers in a cluster which is managed with Torque, you should check out (or create) a “Run Profile” in cisTEM’s settings tab.
You can find a shell script available in following file paths.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}cisTEM with job outputs and errors\PYG{o}{)} /tem/home/tem/\PYGZus{}Applications/cistem\PYGZhy{}1.0.0\PYGZhy{}beta/qsub\PYGZhy{}cisTEM\PYGZhy{}cpu.sh
\PYG{o}{(}cisTEM without outputs and errors\PYG{o}{)}  /tem/home/tem/\PYGZus{}Applications/cistem\PYGZhy{}1.0.0\PYGZhy{}beta/qsub\PYGZhy{}cisTEM\PYGZhy{}cpu\PYGZhy{}noout.sh
\end{sphinxVerbatim}

For qsub-cisTEM-cpu.sh,

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}
\PYG{n+nv}{queue}\PYG{o}{=}
\PYG{k}{while} \PYG{n+nb}{getopts} \PYG{l+s+s2}{\PYGZdq{}:q:\PYGZdq{}} OPTION
\PYG{k}{do}
  \PYG{k}{case} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{OPTION}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}} in
    q\PYG{o}{)} \PYG{n+nv}{queue}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{OPTARG}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{;}\PYG{p}{;}
  \PYG{k}{esac}
\PYG{k}{done}
\PYG{n+nb}{shift} \PYG{k}{\PYGZdl{}((}OPTIND\PYGZhy{}1\PYG{k}{))}

cat \PYGZhy{} \PYG{l+s}{\PYGZlt{}\PYGZlt{}EOF \textbar{} qsub}
\PYG{l+s}{\PYGZsh{}!/bin/bash}
\PYG{l+s}{\PYGZsh{}PBS \PYGZhy{}N cisTEM.\PYGZdl{}\PYGZob{}1\PYGZcb{}}
\PYG{l+s}{\PYGZdl{}\PYGZob{}queue:+\PYGZsh{}PBS \PYGZhy{}l nodes=1:ppn=1:\PYGZdl{}\PYGZob{}queue\PYGZcb{}\PYGZcb{}}
\PYG{l+s}{\PYGZdl{}\PYGZob{}queue:+\PYGZsh{}PBS \PYGZhy{}q \PYGZdl{}\PYGZob{}queue\PYGZcb{}\PYGZcb{}}

\PYG{l+s}{module load apps/gcc/4.4.7/cistem/1.0.0}
\PYG{l+s}{\PYGZdl{}\PYGZob{}@\PYGZcb{}}
\PYG{l+s}{EOF}
\end{sphinxVerbatim}

For qsub-cisTEM-cpu-noout.sh,

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}
\PYG{n+nv}{queue}\PYG{o}{=}
\PYG{k}{while} \PYG{n+nb}{getopts} \PYG{l+s+s2}{\PYGZdq{}:q:\PYGZdq{}} OPTION
\PYG{k}{do}
  \PYG{k}{case} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{OPTION}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}} in
    q\PYG{o}{)} \PYG{n+nv}{queue}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{OPTARG}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{;}\PYG{p}{;}
  \PYG{k}{esac}
\PYG{k}{done}
\PYG{n+nb}{shift} \PYG{k}{\PYGZdl{}((}OPTIND\PYGZhy{}1\PYG{k}{))}

cat \PYGZhy{} \PYG{l+s}{\PYGZlt{}\PYGZlt{}EOF \textbar{} qsub}
\PYG{l+s}{\PYGZsh{}!/bin/bash}
\PYG{l+s}{\PYGZsh{}PBS \PYGZhy{}N cisTEM.\PYGZdl{}\PYGZob{}1\PYGZcb{}}
\PYG{l+s}{\PYGZsh{}PBS \PYGZhy{}e /dev/null}
\PYG{l+s}{\PYGZsh{}PBS \PYGZhy{}o /dev/null}
\PYG{l+s}{\PYGZdl{}\PYGZob{}queue:+\PYGZsh{}PBS \PYGZhy{}l nodes=1:ppn=1:\PYGZdl{}\PYGZob{}queue\PYGZcb{}\PYGZcb{}}
\PYG{l+s}{\PYGZdl{}\PYGZob{}queue:+\PYGZsh{}PBS \PYGZhy{}q \PYGZdl{}\PYGZob{}queue\PYGZcb{}\PYGZcb{}}

\PYG{l+s}{module load apps/gcc/4.4.7/cistem/1.0.0}
\PYG{l+s}{\PYGZdl{}\PYGZob{}@\PYGZcb{}}
\PYG{l+s}{EOF}
\end{sphinxVerbatim}


\subsection{Adding a new Run Profile}
\label{\detokenize{cisTEM:adding-a-new-run-profile}}
In cisTEM settings, add a new “Run Profile” with the following parameters :
\begin{itemize}
\item {} 
Manager Command: /tem/home/tem/\_Applications/cistem-1.0.0-beta/\$command

\item {} 
Gui Address: Automatic

\item {} 
Controller Address: Automatic

\item {} 
Command -\textgreater{} Edit:
\begin{itemize}
\item {} 
Command: /tem/home/tem/\_Applications/cistem-1.0.0-beta/qsub-cisTEM-cpu.sh \sphinxstylestrong{-q \textless{}your\_own\_queue\_name\textgreater{}} \$command

\item {} 
No. Copies: 84

\item {} 
Delay (ms): 10

\end{itemize}

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.6]{{cistem-run-profile-re}.png}\hspace*{\fill}}


\chapter{cryoSPARC}
\label{\detokenize{cryoSPARC:cryosparc}}\label{\detokenize{cryoSPARC::doc}}
CryoSPARC is the state-of-the-art platform used globally for obtaining 3D structural information from single particle cryo-EM data. The cryoSPARC platform enables automated, high quality and high-throughput structure discovery of proteins, viruses and molecular complexes for research and drug discovery. (from CryoSPARC offical site \sphinxurl{https://cryosparc.com})


\chapter{FAQs}
\label{\detokenize{faq:faqs}}\label{\detokenize{faq::doc}}

\chapter{Contacts}
\label{\detokenize{contact:contacts}}\label{\detokenize{contact::doc}}
If you have any questions on using TEM service farm, please do not hesitate to contact us.
\begin{itemize}
\item {} 
Il-Yeon Yeo ( ilyeon9 at kisti.re.kr ) Tel: +82-42-869-0658

\item {} 
Jung-Lok Yu ( junglok.yu at kisti.re.kr ) Tel: +82-42-869-0622

\end{itemize}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}
